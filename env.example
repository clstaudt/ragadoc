# Ollama Instances Configuration
# Format: name1:url1,name2:url2,...
# Examples:
#   OLLAMA_INSTANCES=Local:http://localhost:11434
#   OLLAMA_INSTANCES=Local:http://localhost:11434,Remote:http://192.168.1.100:11434
#   OLLAMA_INSTANCES=Docker Host:http://host.docker.internal:11434,GPU Server:http://10.0.0.5:11434
OLLAMA_INSTANCES=Local:http://localhost:11434

# Note: PageIndex RAG backend (when selected in the UI) automatically configures
# OPENAI_BASE_URL and CHATGPT_API_KEY to use the local Ollama instance.
# No additional API keys are required for the fully local setup. 